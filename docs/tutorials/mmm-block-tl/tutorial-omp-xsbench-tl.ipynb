{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial: Online tuning the OpenMP version of XSBench with transfer learning  \n",
    "===================\n",
    "\n",
    "This tutorial describes how to autotune ECP XSBench app in online tuning settings. \n",
    "\n",
    "We assume that you have checked out a copy of `ytopt` and install `sdv` from [https://github.com/sdv-dev/SDV](https://github.com/sdv-dev/SDV). For guidelines on how to get ytopt and sdv set up, refer [Install instructions](https://github.com/ytopt-team/ytopt/blob/online/README.md). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describing online tuning problem and our approach \n",
    "-----------------------\n",
    "\n",
    "Autotuning refers to the process of generating a search space of possible implementations/configurations of a kernel or an application and evaluating a subset of implementations/configurations on a target platform through empirical measurements to identify the high-performing implementation/configuration. \n",
    "\n",
    "Most tuners are designed for offline tuning. However, tuning online by using the auto-tuner in production is highly needed. \n",
    "\n",
    "In the online tuning settings, how to gather prior knowledge on search space offline and leverage this on a target task real time are the key. To this end, we introduce a generative model that learns the prior information to autotuning a target task online. Procedure of our approach is as follows: \n",
    "- Gather performances of different configurations on source tasks offline \n",
    "- Given the online targe task, use a generative model to learn prior knowledge and suggest a promising configuration in production. \n",
    "\n",
    "In this tutorial, we present our approach to autotune ECP XSBench app `<https://github.com/ANL-CESAR/XSBench>`.\n",
    "\n",
    "XSBench is a mini-app representing a key computational kernel of the Monte Carlo neutron transport algorithm [(reference)](https://github.com/ANL-CESAR/XSBench). Especially, it is the continuous energy macroscopic neutron cross section lookup kernel. XSBench supports the following command line options such as `-m` for Simulation method, `-g` for the number of gridpoints per nuclide, and `-m` for the number of Cross-section (XS) lookups. \n",
    "\n",
    "In this tutorual, we use different lookup sizes to define source offline and target online tasks. \n",
    "\n",
    "- We use the sizes of lookups of 100000, 1000000, 5000000 for offline tuning tasks and 10000000 for online tuning task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autotuning source tasks offline\n",
    "-----------------------\n",
    "First, we autotune source tasks offline based on `ytopt` bayesian optimization (BO) search with Random Forest surrogate model.\n",
    "\n",
    "If you are not familiar with `ytopt` BO search. Please first follow a tutorial in <https://github.com/ytopt-team/ytopt/blob/online/docs/tutorials/omp-xsbench/tutorial-omp-xsbench.md>\n",
    "\n",
    "\n",
    "Our search space contains three parameters: 1) `p0`: number of threads, 2) `p1`: block size for openmp dynamic schedule, 3) `p2`: turn on/off omp parallel.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an object of ConfigSpace \n",
    "cs = CS.ConfigurationSpace(seed=1234)\n",
    "# number of threads\n",
    "p0= CSH.UniformIntegerHyperparameter(name='p0', lower=2, upper=128, default_value=128)\n",
    "#block size for openmp dynamic schedule\n",
    "p1= CSH.OrdinalHyperparameter(name='p1', sequence=['10','20','40','64','80','100','128','160','200'], default_value='100')\n",
    "#omp parallel\n",
    "p2= CSH.CategoricalHyperparameter(name='p2', choices=[\"#pragma omp parallel for\", \" \"], default_value=' ')\n",
    "#add parameters to search space object\n",
    "cs.add_hyperparameters([p0, p1, p2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a search problem for each source task:\n",
    "- `https://github.com/ytopt-team/ytopt/blob/online/ytopt/benchmark/xsbench-omp-tl/xsbench/problem_s.py`\n",
    "- `https://github.com/ytopt-team/ytopt/blob/online/ytopt/benchmark/xsbench-omp-tl/xsbench/problem_m.py`  \n",
    "- `https://github.com/ytopt-team/ytopt/blob/online/ytopt/benchmark/xsbench-omp-tl/xsbench/problem_l.py`  \n",
    "\n",
    "and an evaluating method (Plopper) for code generation and compilation:\n",
    "- `https://github.com/ytopt-team/ytopt/blob/online/ytopt/benchmark/xsbench-omp-tl/plopper/plopper_s.py`\n",
    "- `https://github.com/ytopt-team/ytopt/blob/online/ytopt/benchmark/xsbench-omp-tl/plopper/plopper_m.py`\n",
    "- `https://github.com/ytopt-team/ytopt/blob/online/ytopt/benchmark/xsbench-omp-tl/plopper/plopper_l.py`\n",
    "\n",
    "and a perl file to computes average the execution time:\n",
    "- `https://github.com/ytopt-team/ytopt/blob/online/ytopt/benchmark/xsbench-omp-tl/xsbench/exe_s.pl`  \n",
    "- `https://github.com/ytopt-team/ytopt/blob/online/ytopt/benchmark/xsbench-omp-tl/xsbench/exe_m.pl`  \n",
    "- `https://github.com/ytopt-team/ytopt/blob/online/ytopt/benchmark/xsbench-omp-tl/xsbench/exe_l.pl`  \n",
    " \n",
    " \n",
    "<!-- [Source task 1 (s): 100000 lookups](https://github.com/ytopt-team/ytopt/blob/online/ytopt/benchmark/xsbench-omp-tl/xsbench/problem_s.py)  \n",
    "[Source task 2 (m): 1000000 lookups](https://github.com/ytopt-team/ytopt/blob/online/ytopt/benchmark/xsbench-omp-tl/xsbench/problem_m.py) \n",
    "[Source task 3 (l): 5000000 lookups](https://github.com/ytopt-team/ytopt/blob/online/ytopt/benchmark/xsbench-omp-tl/xsbench/problem_l.py)  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the following command to autotune each task: \n",
    "\n",
    "Go to where the tuning problem is located such as\n",
    "- `cd ytopt/benchmark/xsbench-omp-tl/xsbench`\n",
    "\n",
    "And start search    \n",
    "- `python -m ytopt.search.ambs --evaluator ray --problem problem_s.Problem --max-evals=100 --learner RF`\n",
    "- `python -m ytopt.search.ambs --evaluator ray --problem problem_m.Problem --max-evals=100 --learner RF`\n",
    "- `python -m ytopt.search.ambs --evaluator ray --problem problem_l.Problem --max-evals=100 --learner RF`\n",
    "\n",
    "Once the search is finished, place the csv files in the same folder:\n",
    "- `https://github.com/ytopt-team/ytopt/blob/online/ytopt/benchmark/xsbench-omp-tl/xsbench/results_rf_s_xsbench.csv`\n",
    "- `https://github.com/ytopt-team/ytopt/blob/online/ytopt/benchmark/xsbench-omp-tl/xsbench/results_rf_m_xsbench.csv` \n",
    "- `https://github.com/ytopt-team/ytopt/blob/online/ytopt/benchmark/xsbench-omp-tl/xsbench/results_rf_l_xsbench.csv`\n",
    "\n",
    "`https://github.com/ytopt-team/ytopt/blob/online/ytopt/benchmark/xsbench-omp-tl/xsbench/run.sh` is the run file to do all searches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autotuning target task online\n",
    "-----------------------\n",
    "\n",
    "Now, we describe a standalone code to autotune a target task online `<https://github.com/ytopt-team/ytopt/blob/online/ytopt/benchmark/xsbench-omp-tl/xsbench/Run_online_TL.py>` \n",
    "\n",
    "It provides options: --max-evals flag sets the maximum number of evaluations, --n_refit flag sets how often to refit the generative model, --top flag sets how many of data from source tasks to use to train the generative model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define the objective function `myobj` to evaluate a point in the search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=['p0','p1','p2']\n",
    "def myobj(point: dict):\n",
    "    def plopper_func(x):\n",
    "        x = np.asarray_chkfinite(x)  # ValueError if any NaN or Inf\n",
    "        value = [point[x1[0]],point[x1[1]],point[x1[2]]]\n",
    "        print('CONFIG:',point)\n",
    "        params = [\"P0\",\"P1\",\"P2\"]\n",
    "        result = obj.findRuntime(value, params)\n",
    "        return result\n",
    "    x = np.array([point[f'p{i}'] for i in range(len(point))])\n",
    "    results = plopper_func(x)\n",
    "    print('OUTPUT:%f',results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load data from source tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_opt = []\n",
    "cutoff_p = TOP\n",
    "param_names = x1\n",
    "n_param = len(param_names)\n",
    "frames = []\n",
    "input_sizes = {}\n",
    "input_sizes['s']  = [100000] \n",
    "input_sizes['m']  = [1000000]\n",
    "input_sizes['l']  = [5000000]\n",
    "input_sizes['xl'] = [10000000]\n",
    "\n",
    "for i_size in ['s','m','l']:\n",
    "    dataframe = pd.read_csv(dir_path+\"/results_rf_\"+str(i_size)+\"_xsbench.csv\")  \n",
    "    dataframe['runtime'] = np.log(dataframe['objective']) # log(run time)\n",
    "    dataframe['input']   = pd.Series(input_sizes[i_size][0] for _ in range(len(dataframe.index)))\n",
    "    q_10_s = np.quantile(dataframe.runtime.values, cutoff_p)\n",
    "    real_df = dataframe.loc[dataframe['runtime'] <= q_10_s]\n",
    "    real_data = real_df.drop(columns=['elapsed_sec'])\n",
    "    real_data = real_data.drop(columns=['objective'])\n",
    "    frames.append(real_data)        \n",
    "real_data   = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define a generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_input = Between(\n",
    "    column='input',\n",
    "    low=1,\n",
    "    high=2100000000,\n",
    "    )\n",
    "\n",
    "model = GaussianCopula(\n",
    "            field_names = ['input','p0','p1','p2','runtime'],    \n",
    "            field_transformers = {'input': 'integer',\n",
    "                                  'p0': 'categorical',\n",
    "                                  'p1': 'categorical',\n",
    "                                  'p2': 'categorical',\n",
    "                                  'runtime': 'float'},\n",
    "            constraints=[constraint_input],\n",
    "            min_value =None,\n",
    "            max_value =None\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fit the generative model and suggested configurations are evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Max_evals = MAX_EVALS\n",
    "eval_master = 0\n",
    "while eval_master < Max_evals:         \n",
    "    # update model\n",
    "    model.fit(real_data)\n",
    "    conditions = {'input': input_sizes[TARGET_task][0]}\n",
    "    ss1 = model.sample(max(1000,Max_evals),conditions=conditions)\n",
    "    ss  = ss1.sort_values(by='runtime')\n",
    "    new_sdv = ss[:Max_evals]\n",
    "    max_evals = N_REFIT\n",
    "    eval_update = 0\n",
    "    stop = False\n",
    "    while stop == False:\n",
    "        for row in new_sdv.iterrows():\n",
    "            if eval_update == max_evals:\n",
    "                stop = True\n",
    "                break    \n",
    "            sample_point_val = row[1].values[1:]\n",
    "            sample_point = {x1[0]:sample_point_val[0],\n",
    "                        x1[1]:sample_point_val[1],\n",
    "                        x1[2]:sample_point_val[2]}\n",
    "            res          = myobj(sample_point)\n",
    "            print (sample_point, res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Start search\n",
    "\n",
    "`python Run_online_TL.py --max_evals 10 --n_refit 10 --target xl --top 0.3`\n",
    "\n",
    "Look up the best configuration (found so far) and its value by inspecting the following created file: `results_sdv.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result shows search by and our model based online tuning. It shows tha our approach finds a high perfoming confiruation at the beginning of the search. \n",
    "\n",
    "<!-- ![xsbench tl](xsbench_tl.png) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
